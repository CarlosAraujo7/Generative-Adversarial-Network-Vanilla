{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Aplicação da GAN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Gerador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class Gerador(nn.Module):\n",
    "    \"\"\"\n",
    "    O gerador recebe um vetor de entrada (contendo números aleatórios) e mapeia para o espaço de saída desejado, \n",
    "    produzindo um registro sintético.\n",
    "\n",
    "    Parâmetros:\n",
    "        - tamanho_entrada (int): O tamanho do vetor de entrada, que representa a dimensão do espaço latente.\n",
    "        - tamanho_saida (int): O tamanho do vetor de saída, que representa a dimensão do registro sintético.\n",
    "        - min_values (torch.Tensor): O tensor contendo os valores mínimos para cada coluna do dataframe original.\n",
    "        - max_values (torch.Tensor): O tensor contendo os valores máximos para cada coluna do dataframe original.\n",
    "        - coluna_indices (int): O índice da coluna que precisa ser ajustado para valores específicos.\n",
    "        - valores_possiveis (list): A lista de valores possíveis para a coluna específica.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, tamanho_entrada, tamanho_saida, min_values, max_values, coluna_indices, valores_possiveis):\n",
    "        super(Gerador, self).__init__()\n",
    "        \n",
    "        # Definição da arquitetura do modelo\n",
    "        self.modelo = nn.Sequential(\n",
    "            nn.Linear(tamanho_entrada, 128), # Primeira camada de entrada (linear)\n",
    "            nn.ReLU(), # Capacitar não-linearidade\n",
    "            nn.Linear(128, tamanho_saida), # Segunda camada de saída\n",
    "            nn.Tanh() # Valores de saída no intervalo de (-1 e 1)\n",
    "        )\n",
    "        \n",
    "        self.min_values = min_values\n",
    "        self.max_values = max_values\n",
    "        self.coluna_indices = coluna_indices\n",
    "        self.valores_possiveis = torch.tensor(valores_possiveis)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Essa função passar os dados de entrada através do modelo. Recebe o tensor de entrada \"x (torch.Tensor)\" e retorna\n",
    "        o tensor de saída gerada pelo modelo. Em PyTorch, tensor são unidades básicas para trabalhar com redes neurais.\n",
    "\n",
    "        Parâmetros:\n",
    "            - x (torch.Tensor): O tensor de entrada.\n",
    "        \"\"\"\n",
    "        # Passa os dados pelo modelo\n",
    "        output = self.modelo(x)\n",
    "\n",
    "        # Restringe os valores gerados para estar dentro dos limites observados em cada coluna\n",
    "        output = (output + 1) * 0.5  # Mapeia para o intervalo (0, 1). Conforme está o DF normalizado\n",
    "        output = output * (self.max_values - self.min_values) + self.min_values\n",
    "        \n",
    "        # Ajustar os valores da coluna específica para os valores mais próximos na lista fornecida\n",
    "        output[:, self.coluna_indices] = self._ajustar_para_valores_possiveis(output[:, self.coluna_indices])\n",
    "        \n",
    "        return output\n",
    "\n",
    "    def _ajustar_para_valores_possiveis(self, coluna_valores):\n",
    "        \"\"\"\n",
    "        Ajusta os valores da coluna para os valores mais próximos na lista de valores possíveis.\n",
    "\n",
    "        Parâmetros:\n",
    "            - coluna_valores (torch.Tensor): O tensor contendo os valores da coluna a serem ajustados.\n",
    "\n",
    "        Retorna:\n",
    "            - torch.Tensor: O tensor ajustado com os valores mais próximos na lista de valores possíveis.\n",
    "        \"\"\"\n",
    "        distancias = torch.abs(coluna_valores.unsqueeze(1) - self.valores_possiveis.unsqueeze(0))\n",
    "        indices_mais_proximos = torch.argmin(distancias, dim=1)\n",
    "        valores_ajustados = self.valores_possiveis[indices_mais_proximos]\n",
    "        return valores_ajustados\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Discriminador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminador(nn.Module):\n",
    "    \"\"\"\n",
    "    Esta classe recebe um vetor de entrada (representando um registro) e produz uma única saída, \n",
    "    que representa a probabilidade do registro ser real.\n",
    "\n",
    "    Parâmetros:\n",
    "        - tamanho_entrada (int): O tamanho do vetor de entrada, que representa a dimensão do registro.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, tamanho_entrada):\n",
    "        super(Discriminador, self).__init__()\n",
    "\n",
    "        # Definição da arquitetura do modelo\n",
    "        self.modelo = nn.Sequential(\n",
    "            nn.Linear(tamanho_entrada, 128), # Primeira camada de entrada (linear)\n",
    "            nn.ReLU(), # Capacitar não-linearidade\n",
    "            nn.Linear(128, 1), \n",
    "            nn.Sigmoid() # Saídas em (0 e 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Essa função passar os dados de entrada através do modelo. Recebe o tensor de entrada \"x (torch.Tensor)\" e retorna\n",
    "        o tensor de saída que da a probabilidade do registro ser real. \n",
    "        \n",
    "        Parâmetros:\n",
    "            - x (torch.Tensor): O tensor de entrada.\n",
    "        \"\"\"\n",
    "        return self.modelo(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Treinando o discriminador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "def treinar_discriminador(discriminador, otimizador, dados_reais, dados_falsos):\n",
    "    otimizador.zero_grad() # Zera os gradientes\n",
    "    previsao_real = discriminador(dados_reais) # Passando as 7 instâncias originais pro discriminador\n",
    "    perda_real = criterio(previsao_real, torch.ones_like(previsao_real)) # Próximo de 1 = verdadeiro, próximo de 0 = falso\n",
    "    perda_real.backward() # Algoritmo de backpropagation (Feed-Forward e Feed-Backward)\n",
    "\n",
    "    previsao_falsa = discriminador(dados_falsos)\n",
    "    perda_falsa = criterio(previsao_falsa, torch.zeros_like(previsao_falsa)) # Próximo de 0 = verdadeiro, próximo de 1 = falso\n",
    "    perda_falsa.backward()\n",
    "\n",
    "    otimizador.step() # Atualiza os gradientes\n",
    "\n",
    "    return perda_real + perda_falsa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Treinando o gerador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "def treinar_gerador(gerador, otimizador, dados_falsos): # Etapa de duelo entre o gerador e o discriminador\n",
    "    otimizador.zero_grad()\n",
    "    previsao = discriminador(dados_falsos) \n",
    "    perda = criterio(previsao, torch.ones_like(previsao))\n",
    "    perda.backward()\n",
    "    otimizador.step()\n",
    "    return perda"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Função de normalização"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalizar(df): # Garante que os dados estejam no intervalo de (0 e 1)\n",
    "    return (df - df.min()) / (df.max() - df.min())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Função de desnormalização"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "def desnormalizar(df, df_normalizado): # Retorna os valores ao original\n",
    "    return df_normalizado * (df.max() - df.min()) + df.min()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Normalizando os dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_normalizado = normalizar(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Definindo dimensões"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "tamanho_entrada = len(df.columns)  # Aplica em todas as colunas da base de dados (24)\n",
    "tamanho_saida = tamanho_entrada"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Ajuste de hiperparâmetros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "numero_epocas = 5000 # Quantidade de iterações em cima da base\n",
    "tamanho_batch = 32 # Dados divididos em lotes\n",
    "\n",
    "taxa_aprendizado = 0.0001\n",
    "quantidade_novos_registros = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcular_min_max(df):\n",
    "    \"\"\"\n",
    "    Calcula os valores mínimos e máximos de cada coluna do dataframe.\n",
    "\n",
    "    Parâmetros:\n",
    "        - df (pandas.DataFrame): O dataframe contendo os dados.\n",
    "\n",
    "    Retorna:\n",
    "        - min_values (torch.Tensor): O tensor contendo os valores mínimos para cada coluna.\n",
    "        - max_values (torch.Tensor): O tensor contendo os valores máximos para cada coluna.\n",
    "    \"\"\"\n",
    "    min_values = torch.tensor(df.min().values, dtype=torch.float32)\n",
    "    max_values = torch.tensor(df.max().values, dtype=torch.float32)\n",
    "    return min_values, max_values\n",
    "\n",
    "min_values, max_values = calcular_min_max(df_normalizado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iniciando o gerador e o discriminador\n",
    "gerador = Gerador(tamanho_entrada, tamanho_saida, min_values, max_values, 4, [0, 1])\n",
    "discriminador = Discriminador(tamanho_entrada)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definindo a função de perda\n",
    "criterio = nn.BCELoss() # Entropia cruzada para casos binários\n",
    "\n",
    "# Definindo os otimizadores\n",
    "otimizador_gerador = optim.Adam(gerador.parameters(), lr=taxa_aprendizado) # Estava usando antes o (SGD)\n",
    "otimizador_discriminador = optim.Adam(discriminador.parameters(), lr=taxa_aprendizado)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Treinando a GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.autograd.set_detect_anomaly(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoca in range(numero_epocas):\n",
    "    for i in range(0, len(df_normalizado), tamanho_batch):\n",
    "        # Colocando os dados reais no formato que o PyTorch interpreta\n",
    "        dados_reais = torch.tensor(df_normalizado.iloc[i:i+tamanho_batch].values, dtype=torch.float32)\n",
    "        \n",
    "        # Dados falsos feitos pelo Gerador\n",
    "        ruido = torch.randn(tamanho_batch, tamanho_entrada)\n",
    "        dados_falsos = gerador(ruido)\n",
    "\n",
    "        # Treinando o Discriminador\n",
    "        perda_discriminador = treinar_discriminador(discriminador, otimizador_discriminador, dados_reais, dados_falsos)\n",
    "\n",
    "        # Treinando o Gerador\n",
    "        ruido = torch.randn(tamanho_batch, tamanho_entrada)\n",
    "        dados_falsos = gerador(ruido)\n",
    "        perda_gerador = treinar_gerador(gerador, otimizador_gerador, dados_falsos)\n",
    "\n",
    "    # Imprimir progresso a cada 100 épocas\n",
    "    if (epoca+1) % 100 == 0:\n",
    "        print(f\"Época [{epoca+1}/{numero_epocas}], Perda do Discriminador: {perda_discriminador.item()}, Perda do Gerador: {perda_gerador.item()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Gerando dados sintéticos e aplicando restrições"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gerar dados sintéticos para toda a base de dados\n",
    "novos_registros = []\n",
    "for _ in range(quantidade_novos_registros // tamanho_batch):\n",
    "    ruido = torch.randn(tamanho_batch, tamanho_entrada)\n",
    "    batch_sintetico = gerador(ruido).detach().numpy()\n",
    "\n",
    "    novos_registros.append(batch_sintetico)\n",
    "\n",
    "\n",
    "# Quando o número de dados gerados não é múltiplo do tamanho do batch\n",
    "dados_restantes = quantidade_novos_registros % tamanho_batch\n",
    "if dados_restantes > 0:\n",
    "    ruido = torch.randn(dados_restantes, tamanho_entrada)\n",
    "    batch_sintetico = gerador(ruido).detach().numpy()\n",
    "    \n",
    "    # Restrição 1: Valores negativos iguais a zero\n",
    "    batch_sintetico[batch_sintetico < 0] = 0\n",
    "\n",
    "    novos_registros.append(batch_sintetico)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Desnormalizando e salvando"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "novos_registros = np.concatenate(novos_registros)\n",
    "novos_registros = desnormalizar(df, pd.DataFrame(novos_registros, columns=df.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "novos_registros.to_csv('../registros_gan.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Função para transformar os dados e padronizar conforme o original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transforma_int(coluna):\n",
    "    return int(coluna)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transforma_float(column):\n",
    "    return round(float(column), 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mapear_0_ou_1(valor):\n",
    "    if valor <= 0.5:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mapear_type_of_production(valor):\n",
    "    if valor <= 1.5:\n",
    "        return 1\n",
    "    elif valor <= 2.5:\n",
    "        return 2\n",
    "    else:\n",
    "        return 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Separando as colunas para os tipos de transformação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gan.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "colunas_float = ['height_of_jacket_or_sub-structure (m)', 'height_of_jacket_or_sub-structure (m)', 'risk_to_personnel-complete', 'risk_to_personnel-partial', 'technical_feasibility_or_challenge-complete', 'technical_feasibility_or_challenge-partial', 'commercial_impact_on_fisheries-complete', 'commercial_impact_on_fisheries-partial', 'wider_community_impact-complete', 'wider_community_impact-partial', 'total_removal_cost-complete', 'total_removal_cost-partial', 'impacts_of_option-complete']\n",
    "colunas_int = ['water_depth (m)', 'installation_date', 'weight (t)', 'number_of_legs', 'number_of_piles', 'distance_to_coast (km)', 'energy_consumption-complete (GJ)', 'energy_consumption-partial (GJ)', 'emissions-complete (t)', 'emissions-partial (t)']\n",
    "coluna_mapear_0_ou_1 = ['risk_to_other_users-complete', 'impacts_of_option-partial']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Aplicando as transformações"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_gan['type_of_production (1 oil and gas; 2 oil; 3 gas)'] = df_gan['type_of_production (1 oil and gas; 2 oil; 3 gas)'].apply(mapear_type_of_production)\n",
    "\n",
    "for coluna in colunas_int:\n",
    "    df_gan[coluna] = df_gan[coluna].apply(transforma_int)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Salvando resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gan.to_csv('../dados/registros_gan.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sdmetrics.reports.single_table import QualityReport\n",
    "from sdv.metadata import SingleTableMetadata\n",
    "\n",
    "# Carregar os dados originais e sintéticos\n",
    "df_original = pd.read_csv('../imputed_plataformas_otc.csv')  # Seu dataset original\n",
    "df_sintetico = pd.read_csv('../dados/registros_gan.csv')  # Dados sintéticos gerados\n",
    "\n",
    "metadata_dict = {\n",
    "    \"columns\": {\n",
    "        \"water_depth (m)\": {\n",
    "            \"type\": \"numerical\",\n",
    "            \"pii\": False,\n",
    "            \"sdtype\": \"numerical\"\n",
    "        },\n",
    "        \"weight (t)\": {\n",
    "            \"type\": \"numerical\",\n",
    "            \"pii\": True,\n",
    "            \"sdtype\": \"numerical\"\n",
    "        },\n",
    "        \"installation_date\": {\n",
    "            \"type\": \"numerical\",\n",
    "            \"pii\": False,\n",
    "            \"sdtype\": \"numerical\"\n",
    "        },\n",
    "        \"type_of_production (1 oil and gas; 2 oil; 3 gas)\": {\n",
    "            \"type\": \"numerical\",\n",
    "            \"pii\": False,\n",
    "            \"sdtype\": \"numerical\"\n",
    "        },\n",
    "        \"number_of_legs\": {\n",
    "            \"type\": \"numerical\",\n",
    "            \"pii\": False,\n",
    "            \"sdtype\": \"numerical\"\n",
    "        },\n",
    "        \"number_of_piles\": {\n",
    "            \"type\": \"numerical\",\n",
    "            \"pii\": False,\n",
    "            \"sdtype\": \"numerical\"\n",
    "        },\n",
    "        \"height_of_jacket_or_sub-structure (m)\": {\n",
    "            \"type\": \"numerical\",\n",
    "            \"pii\": False,\n",
    "            \"sdtype\": \"numerical\"\n",
    "        },\n",
    "        \"distance_to_coast (km)\": {\n",
    "            \"type\": \"numerical\",\n",
    "            \"pii\": True,\n",
    "            \"sdtype\": \"numerical\"\n",
    "        },\n",
    "        \"energy_consumption-complete (GJ)\": {\n",
    "            \"type\": \"numerical\",\n",
    "            \"pii\": True,\n",
    "            \"sdtype\": \"numerical\"\n",
    "        },\n",
    "        \"energy_consumption-partial (GJ)\": {\n",
    "            \"type\": \"numerical\",\n",
    "            \"pii\": True,\n",
    "            \"sdtype\": \"numerical\"\n",
    "        },\n",
    "        \"emissions-complete (t)\": {\n",
    "            \"type\": \"numerical\",\n",
    "            \"pii\": True,\n",
    "            \"sdtype\": \"numerical\"\n",
    "        },\n",
    "        \"emissions-partial (t)\": {\n",
    "            \"type\": \"numerical\",\n",
    "            \"pii\": True,\n",
    "            \"sdtype\": \"numerical\"\n",
    "        },\n",
    "        \"recommended (1 partial; 2 complete)\": {\n",
    "            \"type\": \"numerical\",\n",
    "            \"pii\": True,\n",
    "            \"sdtype\": \"numerical\"\n",
    "        }\n",
    "    },\n",
    "    \"primary_key\": \"water_depth (m)\",\n",
    "    \"METADATA_SPEC_VERSION\": \"SINGLE_TABLE_V1\"\n",
    "}\n",
    "\n",
    "# Gerar o relatório de qualidade entre os dados reais e sintéticos\n",
    "report = QualityReport()\n",
    "report.generate(real_data=df_original, synthetic_data=df_sintetico, metadata=metadata_dict)\n",
    "\n",
    "# Exibir detalhes específicos do relatório\n",
    "print(report.get_details(property_name='Column Shapes'))\n",
    "print(report.get_details(property_name='Column Pair Trends'))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
